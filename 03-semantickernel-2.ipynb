{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2fd0938",
   "metadata": {},
   "source": [
    "# Plugins Quickstart\n",
    "\n",
    "[What is a Plugin?](https://learn.microsoft.com/en-us/semantic-kernel/concepts/plugins/?pivots=programming-language-python#importing-different-types-of-plugins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fbc7e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "21baf023",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5a66390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from typing import TypedDict, Annotated, List, Optional\n",
    "\n",
    "import asyncio\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureChatPromptExecutionSettings\n",
    "from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
    "from semantic_kernel.contents import ChatHistory, ChatMessageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "#from semantic_kernel.functions import KernelArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e61aef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load variables\n",
    "load_dotenv()\n",
    "\n",
    "# Variables - Azure Services\n",
    "azopenai_ep=os.environ[\"AZURE_OPENAI_ACCOUNT\"]\n",
    "azopenai_key=os.environ[\"AZURE_OPENAI_KEY\"]\n",
    "azopenai_model=os.environ[\"AZURE_OPENAI_MODEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbc89b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightModel(TypedDict):\n",
    "   id: int\n",
    "   name: str\n",
    "   is_on: bool | None\n",
    "   brightness: int | None\n",
    "   hex: str | None\n",
    "\n",
    "class LightsPlugin:\n",
    "   lights: list[LightModel] = [\n",
    "      {\"id\": 1, \"name\": \"Table Lamp\", \"is_on\": False, \"brightness\": 100, \"hex\": \"FF0000\"},\n",
    "      {\"id\": 2, \"name\": \"Porch light\", \"is_on\": False, \"brightness\": 50, \"hex\": \"00FF00\"},\n",
    "      {\"id\": 3, \"name\": \"Chandelier\", \"is_on\": True, \"brightness\": 75, \"hex\": \"0000FF\"},\n",
    "   ]\n",
    "\n",
    "   @kernel_function\n",
    "   async def get_lights(self) -> List[LightModel]:\n",
    "      \"\"\"Gets a list of lights and their current state.\"\"\"\n",
    "      return self.lights\n",
    "\n",
    "   @kernel_function\n",
    "   async def get_state(\n",
    "      self,\n",
    "      id: Annotated[int, \"The ID of the light\"]\n",
    "   ) -> Optional[LightModel]:\n",
    "      \"\"\"Gets the state of a particular light.\"\"\"\n",
    "      for light in self.lights:\n",
    "         if light[\"id\"] == id:\n",
    "               return light\n",
    "      return None\n",
    "\n",
    "   @kernel_function\n",
    "   async def change_state(\n",
    "      self,\n",
    "      id: Annotated[int, \"The ID of the light\"],\n",
    "      new_state: LightModel\n",
    "   ) -> Optional[LightModel]:\n",
    "      \"\"\"Changes the state of the light.\"\"\"\n",
    "      for light in self.lights:\n",
    "         if light[\"id\"] == id:\n",
    "               light[\"is_on\"] = new_state.get(\"is_on\", light[\"is_on\"])\n",
    "               light[\"brightness\"] = new_state.get(\"brightness\", light[\"brightness\"])\n",
    "               light[\"hex\"] = new_state.get(\"hex\", light[\"hex\"])\n",
    "               return light\n",
    "      return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b07d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant > The \"Table Lamp\" is already turned on with a brightness of 100. Let me know if you want any adjustments!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "# Add Azure OpenAI chat completion\n",
    "chat_completion = AzureChatCompletion(\n",
    "   deployment_name=azopenai_model,\n",
    "   api_key=azopenai_key,\n",
    "   endpoint=azopenai_ep\n",
    ")\n",
    "kernel.add_service(chat_completion)\n",
    "\n",
    "# Add a plugin (the LightsPlugin class is defined below)\n",
    "kernel.add_plugin(\n",
    "   LightsPlugin(),\n",
    "   plugin_name=\"Lights\",\n",
    ")\n",
    "\n",
    "# Enable planning\n",
    "execution_settings = AzureChatPromptExecutionSettings()\n",
    "execution_settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "# Create a history of the conversation\n",
    "history = ChatHistory()\n",
    "history.add_message(\n",
    "   ChatMessageContent(\n",
    "      role=AuthorRole.USER,\n",
    "      content=\"Tell me the current state of the lamp, then turn on the lamp\"\n",
    "   )\n",
    ")\n",
    "\n",
    "# Get the response from the AI\n",
    "result = await chat_completion.get_chat_message_content(\n",
    "   chat_history=history,\n",
    "   settings=execution_settings,\n",
    "   kernel=kernel,\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(\"Assistant: \" + str(result))\n",
    "\n",
    "# Add the message from the agent to the chat history\n",
    "history.add_message(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "118fc43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The current state of the \"Table Lamp\" is as follows:\n",
      "- **State**: OFF\n",
      "- **Brightness**: 100\n",
      "- **Color**: #FF0000 (red)\n",
      "\n",
      "Since the lamp is already off, there's no need to turn it off again. Let me know if you'd like further assistance!\n"
     ]
    }
   ],
   "source": [
    "# Create a history of the conversation\n",
    "history = ChatHistory()\n",
    "history.add_message(\n",
    "   ChatMessageContent(\n",
    "      role=AuthorRole.USER,\n",
    "      content=\"Tell me the current state of the lamp, then turn off the lamp\"\n",
    "   )\n",
    ")\n",
    "\n",
    "# Get the response from the AI\n",
    "result = await chat_completion.get_chat_message_content(\n",
    "   chat_history=history,\n",
    "   settings=execution_settings,\n",
    "   kernel=kernel,\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(\"Assistant: \" + str(result))\n",
    "\n",
    "# Add the message from the agent to the chat history\n",
    "history.add_message(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
